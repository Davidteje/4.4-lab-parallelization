data-lineage-wikipedia-data-lineage-from-wikipedia-the-free-encyclopedia-jump-to-navigation-jump-to-search-origins-and-events-of-data-this-article-contains-wording-that-promotes-the-subject-in-a-subjective-manner-without-imparting-real-information-please-remove-or-replace-such-wording-and-instead-of-making-proclamations-about-a-subject-s-importance-use-facts-and-attribution-to-demonstrate-that-importance-may-2015-learn-how-and-when-to-remove-this-template-message-data-lineage-includes-the-data-origin-what-happens-to-it-and-where-it-moves-over-time-1-data-lineage-gives-visibility-while-greatly-simplifying-the-ability-to-trace-errors-back-to-the-root-cause-in-a-data-analytics-process-2-it-also-enables-replaying-specific-portions-or-inputs-of-the-data-flow-for-step-wise-debugging-or-regenerating-lost-output-database-systems-use-such-information-called-data-provenance-to-address-similar-validation-and-debugging-challenges-3-data-provenance-refers-to-records-of-the-inputs-entities-systems-and-processes-that-influence-data-of-interest-providing-a-historical-record-of-the-data-and-its-origins-the-generated-evidence-supports-forensic-activities-such-as-data-dependency-analysis-error-compromise-detection-and-recovery-auditing-and-compliance-analysis-lineage-is-a-simple-type-of-why-provenance-3-data-lineage-can-be-represented-visually-to-discover-the-data-flow-movement-from-its-source-to-destination-via-various-changes-and-hops-on-its-way-in-the-enterprise-environment-how-the-data-gets-transformed-along-the-way-how-the-representation-and-parameters-change-and-how-the-data-splits-or-converges-after-each-hop-a-simple-representation-of-the-data-lineage-can-be-shown-with-dots-and-lines-where-dot-represents-a-data-container-for-data-points-and-lines-connecting-them-represents-the-transformations-the-data-point-undergoes-between-the-data-containers-representation-broadly-depends-on-scope-of-the-metadata-management-and-reference-point-of-interest-data-lineage-provides-sources-of-the-data-and-intermediate-data-flow-hops-from-the-reference-point-with-backward-data-lineage-leads-to-the-final-destination-s-data-points-and-its-intermediate-data-flows-with-forward-data-lineage-these-views-can-be-combined-with-end-to-end-lineage-for-a-reference-point-that-provides-complete-audit-trail-of-that-data-point-of-interest-from-sources-to-its-final-destinations-as-the-data-points-or-hops-increases-the-complexity-of-such-representation-becomes-incomprehensible-thus-the-best-feature-of-the-data-lineage-view-would-be-to-be-able-to-simplify-the-view-by-temporarily-masking-unwanted-peripheral-data-points-tools-that-have-the-masking-feature-enables-scalability-of-the-view-and-enhances-analysis-with-best-user-experience-for-both-technical-and-business-users-data-lineage-also-enables-companies-to-trace-sources-of-specific-business-data-for-the-purposes-of-tracking-errors-implementing-changes-in-processes-and-implementing-system-migrations-to-save-significant-amounts-of-time-and-resources-thereby-tremendously-improving-bi-efficiency-4-the-scope-of-the-data-lineage-determines-the-volume-of-metadata-required-to-represent-its-data-lineage-usually-data-governance-and-data-management-determines-the-scope-of-the-data-lineage-based-on-their-regulations-enterprise-data-management-strategy-data-impact-reporting-attributes-and-critical-data-elements-of-the-organization-data-lineage-provides-the-audit-trail-of-the-data-points-at-the-highest-granular-level-but-presentation-of-the-lineage-may-be-done-at-various-zoom-levels-to-simplify-the-vast-information-similar-to-analytic-web-maps-data-lineage-can-be-visualized-at-various-levels-based-on-the-granularity-of-the-view-at-a-very-high-level-data-lineage-provides-what-systems-the-data-interacts-before-it-reaches-destination-as-the-granularity-increases-it-goes-up-to-the-data-point-level-where-it-can-provide-the-details-of-the-data-point-and-its-historical-behavior-attribute-properties-and-trends-and-data-quality-of-the-data-passed-through-that-specific-data-point-in-the-data-lineage-data-governance-plays-a-key-role-in-metadata-management-for-guidelines-strategies-policies-implementation-data-quality-and-master-data-management-helps-in-enriching-the-data-lineage-with-more-business-value-even-though-the-final-representation-of-data-lineage-is-provided-in-one-interface-but-the-way-the-metadata-is-harvested-and-exposed-to-the-data-lineage-graphical-user-interface-could-be-entirely-different-thus-data-lineage-can-be-broadly-divided-into-three-categories-based-on-the-way-metadata-is-harvested-data-lineage-involving-software-packages-for-structured-data-programming-languages-and-big-data-data-lineage-information-includes-technical-metadata-involving-data-transformations-enriched-data-lineage-information-may-include-data-quality-test-results-reference-data-values-data-models-business-vocabulary-data-stewards-program-management-information-and-enterprise-information-systems-linked-to-the-data-points-and-transformations-masking-feature-in-the-data-lineage-visualization-allows-the-tools-to-incorporate-all-the-enrichments-that-matter-for-the-specific-use-case-to-represent-disparate-systems-into-one-common-view-metadata-normalization-or-standardization-may-be-necessary-contents-1-rationale-1-1-big-data-debugging-1-2-challenges-in-big-data-debugging-1-2-1-massive-scale-1-2-2-unstructured-data-1-2-3-proposed-solution-2-data-provenance-3-lineage-capture-4-prescriptive-data-lineage-5-active-versus-lazy-lineage-6-actors-7-associations-8-architecture-9-data-flow-reconstruction-9-1-association-tables-9-2-association-graph-9-2-1-explicitly-specified-links-9-2-2-logically-inferred-links-9-2-3-implicit-links-through-data-set-sharing-9-3-topological-sorting-10-tracing-and-replay-11-challenges-11-1-scalability-11-2-fault-tolerance-11-3-black-box-operators-11-4-efficient-tracing-11-5-sophisticated-replay-11-6-anomaly-detection-12-see-also-13-references-rationale-edit-distributed-systems-like-google-map-reduce-5-microsoft-dryad-6-apache-hadoop-7-an-open-source-project-and-google-pregel-8-provide-such-platforms-for-businesses-and-users-however-even-with-these-systems-big-data-analytics-can-take-several-hours-days-or-weeks-to-run-simply-due-to-the-data-volumes-involved-for-example-a-ratings-prediction-algorithm-for-the-netflix-prize-challenge-took-nearly-20-hours-to-execute-on-50-cores-and-a-large-scale-image-processing-task-to-estimate-geographic-information-took-3-days-to-complete-using-400-cores-9-the-large-synoptic-survey-telescope-is-expected-to-generate-terabytes-of-data-every-night-and-eventually-store-more-than-50-petabytes-while-in-the-bioinformatics-sector-the-largest-genome-12-sequencing-houses-in-the-world-now-store-petabytes-of-data-apiece-10-it-is-very-difficult-for-a-data-scientist-to-trace-an-unknown-or-an-unanticipated-result-big-data-debugging-edit-big-data-analytics-is-the-process-of-examining-large-data-sets-to-uncover-hidden-patterns-unknown-correlations-market-trends-customer-preferences-and-other-useful-business-information-they-apply-machine-learning-algorithms-etc-to-the-data-which-transforms-the-data-due-to-the-humongous-size-of-the-data-there-could-be-unknown-features-in-the-data-possibly-even-outliers-it-is-pretty-difficult-for-a-data-scientist-to-actually-debug-an-unexpected-result-the-massive-scale-and-unstructured-nature-of-data-the-complexity-of-these-analytics-pipelines-and-long-runtimes-pose-significant-manageability-and-debugging-challenges-even-a-single-error-in-these-analytics-can-be-extremely-difficult-to-identify-and-remove-while-one-may-debug-them-by-re-running-the-entire-analytics-through-a-debugger-for-step-wise-debugging-this-can-be-expensive-due-to-the-amount-of-time-and-resources-needed-auditing-and-data-validation-are-other-major-problems-due-to-the-growing-ease-of-access-to-relevant-data-sources-for-use-in-experiments-sharing-of-data-between-scientific-communities-and-use-of-third-party-data-in-business-enterprises-11-12-13-14-these-problems-will-only-become-larger-and-more-acute-as-these-systems-and-data-continue-to-grow-as-such-more-cost-efficient-ways-of-analyzing-data-intensive-scalable-computing-disc-are-crucial-to-their-continued-effective-use-challenges-in-big-data-debugging-edit-massive-scale-edit-according-to-an-emc-idc-study-15-2-8zb-of-data-were-created-and-replicated-in-2012-the-digital-universe-will-double-every-two-years-between-now-and-2020-and-there-will-be-approximately-5-2tb-of-data-for-every-person-in-2020-working-with-this-scale-of-data-has-become-very-challenging-unstructured-data-edit-unstructured-data-usually-refers-to-information-that-doesn-t-reside-in-a-traditional-row-column-database-unstructured-data-files-often-include-text-and-multimedia-content-examples-include-e-mail-messages-word-processing-documents-videos-photos-audio-files-presentations-webpages-and-many-other-kinds-of-business-documents-note-that-while-these-sorts-of-files-may-have-an-internal-structure-they-are-still-considered-unstructured-because-the-data-they-contain-doesn-t-fit-neatly-in-a-database-experts-estimate-that-80-to-90-percent-of-the-data-in-any-organization-is-unstructured-and-the-amount-of-unstructured-data-in-enterprises-is-growing-significantly-often-many-times-faster-than-structured-databases-are-growing-big-data-can-include-both-structured-and-unstructured-data-but-idc-estimates-that-90-percent-of-big-data-is-unstructured-data-16-the-fundamental-challenge-of-unstructured-data-sources-is-that-they-are-difficult-for-non-technical-business-users-and-data-analysts-alike-to-unbox-understand-and-prepare-for-analytic-use-beyond-issues-of-structure-is-the-sheer-volume-of-this-type-of-data-because-of-this-current-data-mining-techniques-often-leave-out-valuable-information-and-make-analyzing-unstructured-data-laborious-and-expensive-17-in-todays-competitive-business-environment-companies-have-to-find-and-analyze-the-relevant-data-they-need-quickly-the-challenge-is-going-through-the-volumes-of-data-and-accessing-the-level-of-detail-needed-all-at-a-high-speed-the-challenge-only-grows-as-the-degree-of-granularity-increases-one-possible-solution-is-hardware-some-vendors-are-using-increased-memory-and-parallel-processing-to-crunch-large-volumes-of-data-quickly-another-method-is-putting-data-in-memory-but-using-a-grid-computing-approach-where-many-machines-are-used-to-solve-a-problem-both-approaches-allow-organizations-to-explore-huge-data-volumes-even-this-level-of-sophisticated-hardware-and-software-few-of-the-image-processing-tasks-in-large-scale-take-a-few-days-to-few-weeks-18-debugging-of-the-data-processing-is-extremely-hard-due-to-long-run-times-a-third-approach-of-advanced-data-discovery-solutions-combines-self-service-data-prep-with-visual-data-discovery-enabling-analysts-to-simultaneously-prepare-and-visualize-data-side-by-side-in-an-interactive-analysis-environment-offered-by-newer-companies-trifacta-alteryx-and-others-19-another-method-to-track-data-lineage-is-spreadsheet-programs-such-as-excel-that-do-offer-users-cell-level-lineage-or-the-ability-to-see-what-cells-are-dependent-on-another-but-the-structure-of-the-transformation-is-lost-similarly-etl-or-mapping-software-provide-transform-level-lineage-yet-this-view-typically-doesnt-display-data-and-is-too-coarse-grained-to-distinguish-between-transforms-that-are-logically-independent-e-g-transforms-that-operate-on-distinct-columns-or-dependent-20-big-data-platforms-have-a-very-complicated-structure-data-is-distributed-among-several-machines-typically-the-jobs-are-mapped-into-several-machines-and-results-are-later-combined-by-reduce-operations-debugging-of-a-big-data-pipeline-becomes-very-challenging-because-of-the-very-nature-of-the-system-it-will-not-be-an-easy-task-for-the-data-scientist-to-figure-out-which-machine-s-data-has-the-outliers-and-unknown-features-causing-a-particular-algorithm-to-give-unexpected-results-proposed-solution-edit-data-provenance-or-data-lineage-can-be-used-to-make-the-debugging-of-big-data-pipeline-easier-this-necessitates-the-collection-of-data-about-data-transformations-the-below-section-will-explain-data-provenance-in-more-detail-data-provenance-edit-data-provenance-provides-a-historical-record-of-the-data-and-its-origins-the-provenance-of-data-which-is-generated-by-complex-transformations-such-as-workflows-is-of-considerable-value-to-scientists-21-from-it-one-can-ascertain-the-quality-of-the-data-based-on-its-ancestral-data-and-derivations-track-back-sources-of-errors-allow-automated-re-enactment-of-derivations-to-update-a-data-and-provide-attribution-of-data-sources-provenance-is-also-essential-to-the-business-domain-where-it-can-be-used-to-drill-down-to-the-source-of-data-in-a-data-warehouse-track-the-creation-of-intellectual-property-and-provide-an-audit-trail-for-regulatory-purposes-the-use-of-data-provenance-is-proposed-in-distributed-systems-to-trace-records-through-a-dataflow-replay-the-dataflow-on-a-subset-of-its-original-inputs-and-debug-data-flows-to-do-so-one-needs-to-keep-track-of-the-set-of-inputs-to-each-operator-which-were-used-to-derive-each-of-its-outputs-although-there-are-several-forms-of-provenance-such-as-copy-provenance-and-how-provenance-14-22-the-information-we-need-is-a-simple-form-of-why-provenance-or-lineage-as-defined-by-cui-et-al-23-lineage-capture-edit-intuitively-for-an-operator-t-producing-output-o-lineage-consists-of-triplets-of-form-i-t-o-where-i-is-the-set-of-inputs-to-t-used-to-derive-o-capturing-lineage-for-each-operator-t-in-a-dataflow-enables-users-to-ask-questions-such-as-which-outputs-were-produced-by-an-input-i-on-operator-t-and-which-inputs-produced-output-o-in-operator-t-3-a-query-that-finds-the-inputs-deriving-an-output-is-called-a-backward-tracing-query-while-one-that-finds-the-outputs-produced-by-an-input-is-called-a-forward-tracing-query-24-backward-tracing-is-useful-for-debugging-while-forward-tracing-is-useful-for-tracking-error-propagation-24-tracing-queries-also-form-the-basis-for-replaying-an-original-dataflow-12-23-24-however-to-efficiently-use-lineage-in-a-disc-system-we-need-to-be-able-to-capture-lineage-at-multiple-levels-or-granularities-of-operators-and-data-capture-accurate-lineage-for-disc-processing-constructs-and-be-able-to-trace-through-multiple-dataflow-stages-efficiently-disc-system-consists-of-several-levels-of-operators-and-data-and-different-use-cases-of-lineage-can-dictate-the-level-at-which-lineage-needs-to-be-captured-lineage-can-be-captured-at-the-level-of-the-job-using-files-and-giving-lineage-tuples-of-form-if-i-m-rjob-of-i-lineage-can-also-be-captured-at-the-level-of-each-task-using-records-and-giving-for-example-lineage-tuples-of-form-k-rr-v-rr-map-k-m-v-m-the-first-form-of-lineage-is-called-coarse-grain-lineage-while-the-second-form-is-called-fine-grain-lineage-integrating-lineage-across-different-granularities-enables-users-to-ask-questions-such-as-which-file-read-by-a-mapreduce-job-produced-this-particular-output-record-and-can-be-useful-in-debugging-across-different-operator-and-data-granularities-within-a-dataflow-3-map-reduce-job-showing-containment-relationships-to-capture-end-to-end-lineage-in-a-disc-system-we-use-the-ibis-model-25-which-introduces-the-notion-of-containment-hierarchies-for-operators-and-data-specifically-ibis-proposes-that-an-operator-can-be-contained-within-another-and-such-a-relationship-between-two-operators-is-called-operator-containment-operator-containment-implies-that-the-contained-or-child-operator-performs-a-part-of-the-logical-operation-of-the-containing-or-parent-operator-3-for-example-a-mapreduce-task-is-contained-in-a-job-similar-containment-relationships-exist-for-data-as-well-called-data-containment-data-containment-implies-that-the-contained-data-is-a-subset-of-the-containing-data-superset-containment-hierarchy-prescriptive-data-lineage-edit-the-concept-of-prescriptive-data-lineage-combines-both-the-logical-model-entity-of-how-that-data-should-flow-with-the-actual-lineage-for-that-instance-26-data-lineage-and-provenance-typically-refers-to-the-way-or-the-steps-a-dataset-took-to-reach-its-current-state-of-data-lineage-as-well-as-all-copies-or-derivatives-however-simply-looking-back-at-the-audit-or-log-correlations-to-determine-the-lineage-from-a-forensic-point-of-view-fails-for-certain-data-management-cases-for-instance-it-is-impossible-to-determine-with-certainty-if-the-route-a-data-workflow-took-was-correct-or-in-compliance-without-the-logic-model-only-by-combining-a-logical-model-with-atomic-forensic-events-can-proper-activities-be-validated-authorized-copies-joins-or-ctas-operations-mapping-of-processing-to-the-systems-that-those-process-are-run-on-ad-hoc-versus-established-processing-sequences-many-certified-compliance-reports-require-provenance-of-data-flow-as-well-as-the-end-state-data-for-a-specific-instance-with-these-types-of-situations-any-deviation-from-the-prescribed-path-need-to-be-accounted-and-potentially-remediated-27-this-marks-a-shift-from-purely-looking-back-to-a-framework-which-is-better-suited-to-capture-compliance-workflows-active-versus-lazy-lineage-edit-lazy-lineage-collection-typically-captures-only-coarse-grain-lineage-at-run-time-these-systems-incur-low-capture-overheads-due-to-the-small-amount-of-lineage-they-capture-however-to-answer-fine-grain-tracing-queries-they-must-replay-the-data-flow-on-all-or-a-large-part-of-its-input-and-collect-fine-grain-lineage-during-the-replay-this-approach-is-suitable-for-forensic-systems-where-a-user-wants-to-debug-an-observed-bad-output-active-collection-systems-capture-entire-lineage-of-the-data-flow-at-run-time-the-kind-of-lineage-they-capture-may-be-coarse-grain-or-fine-grain-but-they-do-not-require-any-further-computations-on-the-data-flow-after-its-execution-active-fine-grain-lineage-collection-systems-incur-higher-capture-overheads-than-lazy-collection-systems-however-they-enable-sophisticated-replay-and-debugging-3-actors-edit-an-actor-is-an-entity-that-transforms-data-it-may-be-a-dryad-vertex-individual-map-and-reduce-operators-a-mapreduce-job-or-an-entire-dataflow-pipeline-actors-act-as-black-boxes-and-the-inputs-and-outputs-of-an-actor-are-tapped-to-capture-lineage-in-the-form-of-associations-where-an-association-is-a-triplet-i-t-o-that-relates-an-input-i-with-an-output-o-for-an-actor-t-the-instrumentation-thus-captures-lineage-in-a-dataflow-one-actor-at-a-time-piecing-it-into-a-set-of-associations-for-each-actor-the-system-developer-needs-to-capture-the-data-an-actor-reads-from-other-actors-and-the-data-an-actor-writes-to-other-actors-for-example-a-developer-can-treat-the-hadoop-job-tracker-as-an-actor-by-recording-the-set-of-files-read-and-written-by-each-job-28-associations-edit-association-is-a-combination-of-the-inputs-outputs-and-the-operation-itself-the-operation-is-represented-in-terms-of-a-black-box-also-known-as-the-actor-the-associations-describe-the-transformations-that-are-applied-on-the-data-the-associations-are-stored-in-the-association-tables-each-unique-actor-is-represented-by-its-own-association-table-an-association-itself-looks-like-i-t-o-where-i-is-the-set-of-inputs-to-the-actor-t-and-o-is-set-of-outputs-given-produced-by-the-actor-associations-are-the-basic-units-of-data-lineage-individual-associations-are-later-clubbed-together-to-construct-the-entire-history-of-transformations-that-were-applied-to-the-data-3-architecture-edit-big-data-systems-scale-horizontally-i-e-increase-capacity-by-adding-new-hardware-or-software-entities-into-the-distributed-system-the-distributed-system-acts-as-a-single-entity-in-the-logical-level-even-though-it-comprises-multiple-hardware-and-software-entities-the-system-should-continue-to-maintain-this-property-after-horizontal-scaling-an-important-advantage-of-horizontal-scalability-is-that-it-can-provide-the-ability-to-increase-capacity-on-the-fly-the-biggest-plus-point-is-that-horizontal-scaling-can-be-done-using-commodity-hardware-the-horizontal-scaling-feature-of-big-data-systems-should-be-taken-into-account-while-creating-the-architecture-of-lineage-store-this-is-essential-because-the-lineage-store-itself-should-also-be-able-to-scale-in-parallel-with-the-big-data-system-the-number-of-associations-and-amount-of-storage-required-to-store-lineage-will-increase-with-the-increase-in-size-and-capacity-of-the-system-the-architecture-of-big-data-systems-makes-the-use-of-a-single-lineage-store-not-appropriate-and-impossible-to-scale-the-immediate-solution-to-this-problem-is-to-distribute-the-lineage-store-itself-3-the-best-case-scenario-is-to-use-a-local-lineage-store-for-every-machine-in-the-distributed-system-network-this-allows-the-lineage-store-also-to-scale-horizontally-in-this-design-the-lineage-of-data-transformations-applied-to-the-data-on-a-particular-machine-is-stored-on-the-local-lineage-store-of-that-specific-machine-the-lineage-store-typically-stores-association-tables-each-actor-is-represented-by-its-own-association-table-the-rows-are-the-associations-themselves-and-columns-represent-inputs-and-outputs-this-design-solves-2-problems-it-allows-horizontal-scaling-of-the-lineage-store-if-a-single-centralized-lineage-store-was-used-then-this-information-had-to-be-carried-over-the-network-which-would-cause-additional-network-latency-the-network-latency-is-also-avoided-by-the-use-of-a-distributed-lineage-store-28-architecture-of-lineage-systems-data-flow-reconstruction-edit-the-information-stored-in-terms-of-associations-needs-to-be-combined-by-some-means-to-get-the-data-flow-of-a-particular-job-in-a-distributed-system-a-job-is-broken-down-into-multiple-tasks-one-or-more-instances-run-a-particular-task-the-results-produced-on-these-individual-machines-are-later-combined-together-to-finish-the-job-tasks-running-on-different-machines-perform-multiple-transformations-on-the-data-in-the-machine-all-the-transformations-applied-to-the-data-on-a-machines-is-stored-in-the-local-lineage-store-of-that-machines-this-information-needs-to-be-combined-together-to-get-the-lineage-of-the-entire-job-the-lineage-of-the-entire-job-should-help-the-data-scientist-understand-the-data-flow-of-the-job-and-he-she-can-use-the-data-flow-to-debug-the-big-data-pipeline-the-data-flow-is-reconstructed-in-3-stages-association-tables-edit-the-first-stage-of-the-data-flow-reconstruction-is-the-computation-of-the-association-tables-the-association-tables-exists-for-each-actor-in-each-local-lineage-store-the-entire-association-table-for-an-actor-can-be-computed-by-combining-these-individual-association-tables-this-is-generally-done-using-a-series-of-equality-joins-based-on-the-actors-themselves-in-few-scenarios-the-tables-might-also-be-joined-using-inputs-as-the-key-indexes-can-also-be-used-to-improve-the-efficiency-of-a-join-the-joined-tables-need-to-be-stored-on-a-single-instance-or-a-machine-to-further-continue-processing-there-are-multiple-schemes-that-are-used-to-pick-a-machine-where-a-join-would-be-computed-the-easiest-one-being-the-one-with-minimum-cpu-load-space-constraints-should-also-be-kept-in-mind-while-picking-the-instance-where-join-would-happen-association-graph-edit-the-second-step-in-data-flow-reconstruction-is-computing-an-association-graph-from-the-lineage-information-the-graph-represents-the-steps-in-the-data-flow-the-actors-act-as-vertices-and-the-associations-act-as-edges-each-actor-t-is-linked-to-its-upstream-and-downstream-actors-in-the-data-flow-an-upstream-actor-of-t-is-one-that-produced-the-input-of-t-while-a-downstream-actor-is-one-that-consumes-the-output-of-t-containment-relationships-are-always-considered-while-creating-the-links-the-graph-consists-of-three-types-of-links-or-edges-explicitly-specified-links-edit-the-simplest-link-is-an-explicitly-specified-link-between-two-actors-these-links-are-explicitly-specified-in-the-code-of-a-machine-learning-algorithm-when-an-actor-is-aware-of-its-exact-upstream-or-downstream-actor-it-can-communicate-this-information-to-lineage-api-this-information-is-later-used-to-link-these-actors-during-the-tracing-query-for-example-in-the-mapreduce-architecture-each-map-instance-knows-the-exact-record-reader-instance-whose-output-it-consumes-3-logically-inferred-links-edit-developers-can-attach-data-flow-archetypes-to-each-logical-actor-a-data-flow-archetype-explains-how-the-children-types-of-an-actor-type-arrange-themselves-in-a-data-flow-with-the-help-of-this-information-one-can-infer-a-link-between-each-actor-of-a-source-type-and-a-destination-type-for-example-in-the-mapreduce-architecture-the-map-actor-type-is-the-source-for-reduce-and-vice-versa-the-system-infers-this-from-the-data-flow-archetypes-and-duly-links-map-instances-with-reduce-instances-however-there-may-be-several-mapreduce-jobs-in-the-data-flow-and-linking-all-map-instances-with-all-reduce-instances-can-create-false-links-to-prevent-this-such-links-are-restricted-to-actor-instances-contained-within-a-common-actor-instance-of-a-containing-or-parent-actor-type-thus-map-and-reduce-instances-are-only-linked-to-each-other-if-they-belong-to-the-same-job-3-implicit-links-through-data-set-sharing-edit-in-distributed-systems-sometimes-there-are-implicit-links-which-are-not-specified-during-execution-for-example-an-implicit-link-exists-between-an-actor-that-wrote-to-a-file-and-another-actor-that-read-from-it-such-links-connect-actors-which-use-a-common-data-set-for-execution-the-dataset-is-the-output-of-the-first-actor-and-is-the-input-of-the-actor-following-it-3-topological-sorting-edit-the-final-step-in-the-data-flow-reconstruction-is-the-topological-sorting-of-the-association-graph-the-directed-graph-created-in-the-previous-step-is-topologically-sorted-to-obtain-the-order-in-which-the-actors-have-modified-the-data-this-inherit-order-of-the-actors-defines-the-data-flow-of-the-big-data-pipeline-or-task-tracing-and-replay-edit-this-is-the-most-crucial-step-in-big-data-debugging-the-captured-lineage-is-combined-and-processed-to-obtain-the-data-flow-of-the-pipeline-the-data-flow-helps-the-data-scientist-or-a-developer-to-look-deeply-into-the-actors-and-their-transformations-this-step-allows-the-data-scientist-to-figure-out-the-part-of-the-algorithm-that-is-generating-the-unexpected-output-a-big-data-pipeline-can-go-wrong-in-two-broad-ways-the-first-is-a-presence-of-a-suspicious-actor-in-the-data-flow-the-second-being-the-existence-of-outliers-in-the-data-the-first-case-can-be-debugged-by-tracing-the-data-flow-by-using-lineage-and-data-flow-information-together-a-data-scientist-can-figure-out-how-the-inputs-are-converted-into-outputs-during-the-process-actors-that-behave-unexpectedly-can-be-caught-either-these-actors-can-be-removed-from-the-data-flow-or-they-can-be-augmented-by-new-actors-to-change-the-data-flow-the-improved-data-flow-can-be-replayed-to-test-the-validity-of-it-debugging-faulty-actors-include-recursively-performing-coarse-grain-replay-on-actors-in-the-data-flow-29-which-can-be-expensive-in-resources-for-long-dataflows-another-approach-is-to-manually-inspect-lineage-logs-to-find-anomalies-13-30-which-can-be-tedious-and-time-consuming-across-several-stages-of-a-data-flow-furthermore-these-approaches-work-only-when-the-data-scientist-can-discover-bad-outputs-to-debug-analytics-without-known-bad-outputs-the-data-scientist-need-to-analyze-the-data-flow-for-suspicious-behavior-in-general-however-often-a-user-may-not-know-the-expected-normal-behavior-and-cannot-specify-predicates-this-section-describes-a-debugging-methodology-for-retrospectively-analyzing-lineage-to-identify-faulty-actors-in-a-multi-stage-data-flow-we-believe-that-sudden-changes-in-an-actors-behavior-such-as-its-average-selectivity-processing-rate-or-output-size-is-characteristic-of-an-anomaly-lineage-can-reflect-such-changes-in-actor-behavior-over-time-and-across-different-actor-instances-thus-mining-lineage-to-identify-such-changes-can-be-useful-in-debugging-faulty-actors-in-a-data-flow-tracing-anomalous-actors-the-second-problem-i-e-the-existence-of-outliers-can-also-be-identified-by-running-the-data-flow-step-wise-and-looking-at-the-transformed-outputs-the-data-scientist-finds-a-subset-of-outputs-that-are-not-in-accordance-to-the-rest-of-outputs-the-inputs-which-are-causing-these-bad-outputs-are-the-outliers-in-the-data-this-problem-can-be-solved-by-removing-the-set-of-outliers-from-the-data-and-replaying-the-entire-data-flow-it-can-also-be-solved-by-modifying-the-machine-learning-algorithm-by-adding-removing-or-moving-actors-in-the-data-flow-the-changes-in-the-data-flow-are-successful-if-the-replayed-data-flow-does-not-produce-bad-outputs-tracing-outliers-in-the-data-challenges-edit-even-though-the-use-of-data-lineage-approaches-is-a-novel-way-of-debugging-of-big-data-pipelines-the-process-is-not-simple-the-challenges-include-scalability-of-the-lineage-store-fault-tolerance-of-the-lineage-store-accurate-capture-of-lineage-for-black-box-operators-and-many-others-these-challenges-must-be-considered-carefully-and-trade-offs-between-them-need-to-be-evaluated-to-make-a-realistic-design-for-data-lineage-capture-scalability-edit-disc-systems-are-primarily-batch-processing-systems-designed-for-high-throughput-they-execute-several-jobs-per-analytics-with-several-tasks-per-job-the-overall-number-of-operators-executing-at-any-time-in-a-cluster-can-range-from-hundreds-to-thousands-depending-on-the-cluster-size-lineage-capture-for-these-systems-must-be-able-scale-to-both-large-volumes-of-data-and-numerous-operators-to-avoid-being-a-bottleneck-for-the-disc-analytics-fault-tolerance-edit-lineage-capture-systems-must-also-be-fault-tolerant-to-avoid-rerunning-data-flows-to-capture-lineage-at-the-same-time-they-must-also-accommodate-failures-in-the-disc-system-to-do-so-they-must-be-able-to-identify-a-failed-disc-task-and-avoid-storing-duplicate-copies-of-lineage-between-the-partial-lineage-generated-by-the-failed-task-and-duplicate-lineage-produced-by-the-restarted-task-a-lineage-system-should-also-be-able-to-gracefully-handle-multiple-instances-of-local-lineage-systems-going-down-this-can-achieved-by-storing-replicas-of-lineage-associations-in-multiple-machines-the-replica-can-act-like-a-backup-in-the-event-of-the-real-copy-being-lost-black-box-operators-edit-lineage-systems-for-disc-dataflows-must-be-able-to-capture-accurate-lineage-across-black-box-operators-to-enable-fine-grain-debugging-current-approaches-to-this-include-prober-which-seeks-to-find-the-minimal-set-of-inputs-that-can-produce-a-specified-output-for-a-black-box-operator-by-replaying-the-data-flow-several-times-to-deduce-the-minimal-set-31-and-dynamic-slicing-as-used-by-zhang-et-al-32-to-capture-lineage-for-nosql-operators-through-binary-rewriting-to-compute-dynamic-slices-although-producing-highly-accurate-lineage-such-techniques-can-incur-significant-time-overheads-for-capture-or-tracing-and-it-may-be-preferable-to-instead-trade-some-accuracy-for-better-performance-thus-there-is-a-need-for-a-lineage-collection-system-for-disc-dataflows-that-can-capture-lineage-from-arbitrary-operators-with-reasonable-accuracy-and-without-significant-overheads-in-capture-or-tracing-efficient-tracing-edit-tracing-is-essential-for-debugging-during-which-a-user-can-issue-multiple-tracing-queries-thus-it-is-important-that-tracing-has-fast-turnaround-times-ikeda-et-al-24-can-perform-efficient-backward-tracing-queries-for-mapreduce-dataflows-but-are-not-generic-to-different-disc-systems-and-do-not-perform-efficient-forward-queries-lipstick-33-a-lineage-system-for-pig-34-while-able-to-perform-both-backward-and-forward-tracing-is-specific-to-pig-and-sql-operators-and-can-only-perform-coarse-grain-tracing-for-black-box-operators-thus-there-is-a-need-for-a-lineage-system-that-enables-efficient-forward-and-backward-tracing-for-generic-disc-systems-and-dataflows-with-black-box-operators-sophisticated-replay-edit-replaying-only-specific-inputs-or-portions-of-a-data-flow-is-crucial-for-efficient-debugging-and-simulating-what-if-scenarios-ikeda-et-al-present-a-methodology-for-lineage-based-refresh-which-selectively-replays-updated-inputs-to-recompute-affected-outputs-35-this-is-useful-during-debugging-for-re-computing-outputs-when-a-bad-input-has-been-fixed-however-sometimes-a-user-may-want-to-remove-the-bad-input-and-replay-the-lineage-of-outputs-previously-affected-by-the-error-to-produce-error-free-outputs-we-call-this-exclusive-replay-another-use-of-replay-in-debugging-involves-replaying-bad-inputs-for-step-wise-debugging-called-selective-replay-current-approaches-to-using-lineage-in-disc-systems-do-not-address-these-thus-there-is-a-need-for-a-lineage-system-that-can-perform-both-exclusive-and-selective-replays-to-address-different-debugging-needs-anomaly-detection-edit-one-of-the-primary-debugging-concerns-in-disc-systems-is-identifying-faulty-operators-in-long-dataflows-with-several-hundreds-of-operators-or-tasks-manual-inspection-can-be-tedious-and-prohibitive-even-if-lineage-is-used-to-narrow-the-subset-of-operators-to-examine-the-lineage-of-a-single-output-can-still-span-several-operators-there-is-a-need-for-an-inexpensive-automated-debugging-system-which-can-substantially-narrow-the-set-of-potentially-faulty-operators-with-reasonable-accuracy-to-minimize-the-amount-of-manual-examination-required-see-also-edit-directed-acyclic-graph-references-edit-what-is-data-lineage-definition-from-techopedia-hoang-natalie-2017-03-16-data-lineage-helps-drives-business-value-trifacta-trifacta-retrieved-2017-09-20-a-b-c-d-e-f-g-h-i-j-k-de-soumyarupa-2012-newt-an-architecture-for-lineage-based-replay-and-debugging-in-disc-systems-uc-san-diego-b7355202-retrieved-from-https-escholarship-org-uc-item-3170p7zn-drori-amanon-2020-05-18-what-is-data-lineage-octopai-octopai-retrieved-2020-08-25-jeffrey-dean-and-sanjay-ghemawat-mapreduce-simplified-data-processing-on-large-clusters-commun-acm-51-1-107-113-january-2008-michael-isard-mihai-budiu-yuan-yu-andrew-birrell-and-dennis-fetterly-dryad-distributed-data-parallel-programs-from-sequential-building-blocks-in-proceedings-of-the-2nd-acm-sigops-eurosys-european-conference-oncomputer-systems-2007-eurosys-07-pages-59-72-new-york-ny-usa-2007-acm-apache-hadoop-http-hadoop-apache-org-grzegorz-malewicz-matthew-h-austern-aart-j-c-bik-james-c-dehnert-ilan-horn-naty-leiser-and-grzegorz-czajkowski-pregel-a-system-for-largescale-graph-processing-in-proceedings-of-the-2010-international-conference-on-managementof-data-sigmod-10-pages-135-146-new-york-ny-usa-2010-acm-shimin-chen-and-steven-w-schlosser-map-reduce-meets-wider-varieties-of-applications-technical-report-intel-research-2008-the-data-deluge-in-genomics-https-www-304-ibm-com-connections-blogs-ibmhealthcare-entry-data-overload-in-genomics3-lang-de-2010-yogesh-l-simmhan-beth-plale-and-dennis-gannon-a-survey-of-data-prove-nance-in-e-science-sigmod-rec-34-3-31-36-september-2005-a-b-ian-foster-jens-vockler-michael-wilde-and-yong-zhao-chimera-a-virtual-data-system-for-representing-querying-and-automating-data-derivation-in-14th-international-conference-on-scientific-and-statistical-database-management-july-2002-a-b-benjamin-h-sigelman-luiz-andr-barroso-mike-burrows-pat-stephenson-manoj-plakal-donald-beaver-saul-jaspan-and-chandan-shanbhag-dapper-a-large-scale-distributed-systems-tracing-infrastructure-technical-report-google-inc-2010-a-b-peter-buneman-sanjeev-khanna-and-wang-chiew-tan-data-provenance-some-basic-issues-in-proceedings-of-the-20th-conference-on-foundations-of-softwaretechnology-and-theoretical-computer-science-fst-tcs-2000-pages-87-93-london-uk-uk-2000-springer-verlag-new-digital-universe-study-reveals-big-data-gap-less-than-1-of-world-s-data-is-analyzed-less-than-20-is-protected-webopedia-http-www-webopedia-com-term-u-unstructured-data-html-schaefer-paige-2016-08-24-differences-between-structured-unstructured-data-trifacta-retrieved-2017-09-20-sas-http-www-sas-com-resources-asset-five-big-data-challenges-article-pdf-archived-2014-12-20-at-the-wayback-machine-5-requirements-for-effective-self-service-data-preparation-www-itbusinessedge-com-18-february-2016-retrieved-2017-09-20-kandel-sean-2016-11-04-tracking-data-lineage-in-financial-services-trifacta-trifacta-retrieved-2017-09-20-pasquier-thomas-lau-matthew-k-trisovic-ana-boose-emery-r-couturier-ben-crosas-merce-ellison-aaron-m-gibson-valerie-jones-chris-r-seltzer-margo-5-september-2017-if-these-data-could-talk-scientific-data-4-170114-bibcode-2017natsd-470114p-doi-10-1038-sdata-2017-114-pmc-5584398-pmid-28872630-robert-ikeda-and-jennifer-widom-data-lineage-a-survey-technical-report-stanford-university-2009-a-b-y-cui-and-j-widom-lineage-tracing-for-general-data-warehouse-transformations-vldb-journal-12-1-2003-a-b-c-d-robert-ikeda-hyunjung-park-and-jennifer-widom-provenance-for-generalized-map-and-reduce-workflows-in-proc-of-cidr-january-2011-c-olston-and-a-das-sarma-ibis-a-provenance-manager-for-multi-layer-systems-in-proc-of-cidr-january-2011-archived-copy-pdf-archived-from-the-original-pdf-on-2015-09-05-retrieved-2015-09-02-cite-web-cs1-maint-archived-copy-as-title-link-sec-small-entity-compliance-guide-a-b-dionysios-logothetis-soumyarupa-de-and-kenneth-yocum-2013-scalable-lineage-capture-for-debugging-disc-analytics-in-proceedings-of-the-4th-annual-symposium-on-cloud-computing-socc-13-acm-new-york-ny-usa-article-17-15-pages-zhou-wenchao-fei-qiong-narayan-arjun-haeberlen-andreas-thau-loo-boon-sherr-micah-december-2011-secure-network-provenance-proceedings-of-23rd-acm-symposium-on-operating-system-principles-sosp-fonseca-rodrigo-porter-george-katz-randy-h-shenker-scott-stoica-ion-2007-x-trace-a-pervasive-network-tracing-framework-proceedings-of-nsdi07-anish-das-sarma-alpa-jain-and-philip-bohannon-prober-ad-hoc-debugging-of-extraction-and-integration-pipelines-technical-report-yahoo-april-2010-mingwu-zhang-xiangyu-zhang-xiang-zhang-and-sunil-prabhakar-tracing-lineage-beyond-relational-operators-in-proc-conference-on-very-large-data-bases-vldb-september-2007-yael-amsterdamer-susan-b-davidson-daniel-deutch-tova-milo-and-julia-stoyanovich-putting-lipstick-on-a-pig-enabling-database-style-workflow-provenance-in-proc-of-vldb-august-2011-christopher-olston-benjamin-reed-utkarsh-srivastava-ravi-kumar-and-andrew-tomkins-pig-latin-a-not-so-foreign-language-for-data-processing-in-proc-of-acm-sigmod-vancouver-canada-june-2008-robert-ikeda-semih-salihoglu-and-jennifer-widom-provenance-based-refresh-in-data-oriented-workflows-in-proceedings-of-the-20th-acm-international-conference-on-information-and-knowledge-management-cikm-11-pages-1659-1668-new-york-ny-usa-2011-acm-retrieved-from-https-en-wikipedia-org-w-index-php-title-data-lineage-oldid-1108848141-categories-data-managementdistributed-computing-problemsbig-datahidden-categories-webarchive-template-wayback-linkscs1-maint-archived-copy-as-titlearticles-with-short-descriptionshort-description-matches-wikidataarticles-with-peacock-terms-from-may-2015all-articles-with-peacock-terms-navigation-menu-personal-tools-not-logged-intalkcontributionscreate-accountlog-in-namespaces-articletalk-english-views-readeditview-history-more-search-navigation-main-pagecontentscurrent-eventsrandom-articleabout-wikipediacontact-usdonate-contribute-helplearn-to-editcommunity-portalrecent-changesupload-file-tools-what-links-hererelated-changesupload-filespecial-pagespermanent-linkpage-informationcite-this-pagewikidata-item-print-export-download-as-pdfprintable-version-languages-deutschfrancais-edit-links-this-page-was-last-edited-on-6-september-2022-at-15-44-utc-text-is-available-under-the-creative-commons-attribution-sharealike-license-3-0-additional-terms-may-apply-by-using-this-site-you-agree-to-the-terms-of-use-and-privacy-policy-wikipedia-r-is-a-registered-trademark-of-the-wikimedia-foundation-inc-a-non-profit-organization-privacy-policy-about-wikipedia-disclaimers-contact-wikipedia-mobile-view-developers-statistics-cookie-statement