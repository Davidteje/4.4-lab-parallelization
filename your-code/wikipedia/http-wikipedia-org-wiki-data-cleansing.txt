data-cleansing-wikipedia-data-cleansing-from-wikipedia-the-free-encyclopedia-jump-to-navigation-jump-to-search-correcting-inaccurate-computer-records-not-to-be-confused-with-sanitization-classified-information-or-data-scrubbing-data-cleansing-or-data-cleaning-is-the-process-of-detecting-and-correcting-or-removing-corrupt-or-inaccurate-records-from-a-record-set-table-or-database-and-refers-to-identifying-incomplete-incorrect-inaccurate-or-irrelevant-parts-of-the-data-and-then-replacing-modifying-or-deleting-the-dirty-or-coarse-data-1-data-cleansing-may-be-performed-interactively-with-data-wrangling-tools-or-as-batch-processing-through-scripting-or-a-data-quality-firewall-after-cleansing-a-data-set-should-be-consistent-with-other-similar-data-sets-in-the-system-the-inconsistencies-detected-or-removed-may-have-been-originally-caused-by-user-entry-errors-by-corruption-in-transmission-or-storage-or-by-different-data-dictionary-definitions-of-similar-entities-in-different-stores-data-cleaning-differs-from-data-validation-in-that-validation-almost-invariably-means-data-is-rejected-from-the-system-at-entry-and-is-performed-at-the-time-of-entry-rather-than-on-batches-of-data-the-actual-process-of-data-cleansing-may-involve-removing-typographical-errors-or-validating-and-correcting-values-against-a-known-list-of-entities-the-validation-may-be-strict-such-as-rejecting-any-address-that-does-not-have-a-valid-postal-code-or-with-fuzzy-or-approximate-string-matching-such-as-correcting-records-that-partially-match-existing-known-records-some-data-cleansing-solutions-will-clean-data-by-cross-checking-with-a-validated-data-set-a-common-data-cleansing-practice-is-data-enhancement-where-data-is-made-more-complete-by-adding-related-information-for-example-appending-addresses-with-any-phone-numbers-related-to-that-address-data-cleansing-may-also-involve-harmonization-or-normalization-of-data-which-is-the-process-of-bringing-together-data-of-varying-file-formats-naming-conventions-and-columns-2-and-transforming-it-into-one-cohesive-data-set-a-simple-example-is-the-expansion-of-abbreviations-st-rd-etc-to-street-road-etcetera-contents-1-motivation-2-data-quality-3-process-4-system-5-quality-screens-6-criticism-of-existing-tools-and-processes-7-error-event-schema-8-see-also-9-references-10-further-reading-11-external-links-motivation-edit-administratively-incorrect-inconsistent-data-can-lead-to-false-conclusions-and-misdirect-investments-on-both-public-and-private-scales-for-instance-the-government-may-want-to-analyze-population-census-figures-to-decide-which-regions-require-further-spending-and-investment-on-infrastructure-and-services-in-this-case-it-will-be-important-to-have-access-to-reliable-data-to-avoid-erroneous-fiscal-decisions-in-the-business-world-incorrect-data-can-be-costly-many-companies-use-customer-information-databases-that-record-data-like-contact-information-addresses-and-preferences-for-instance-if-the-addresses-are-inconsistent-the-company-will-suffer-the-cost-of-resending-mail-or-even-losing-customers-data-quality-edit-high-quality-data-needs-to-pass-a-set-of-quality-criteria-those-include-validity-the-degree-to-which-the-measures-conform-to-defined-business-rules-or-constraints-see-also-validity-statistics-when-modern-database-technology-is-used-to-design-data-capture-systems-validity-is-fairly-easy-to-ensure-invalid-data-arises-mainly-in-legacy-contexts-where-constraints-were-not-implemented-in-software-or-where-inappropriate-data-capture-technology-was-used-e-g-spreadsheets-where-it-is-very-hard-to-limit-what-a-user-chooses-to-enter-into-a-cell-if-cell-validation-is-not-used-data-constraints-fall-into-the-following-categories-data-type-constraints-e-g-values-in-a-particular-column-must-be-of-a-particular-data-type-e-g-boolean-numeric-integer-or-real-date-etc-range-constraints-typically-numbers-or-dates-should-fall-within-a-certain-range-that-is-they-have-minimum-and-or-maximum-permissible-values-mandatory-constraints-certain-columns-cannot-be-empty-unique-constraints-a-field-or-a-combination-of-fields-must-be-unique-across-a-dataset-for-example-no-two-persons-can-have-the-same-social-security-number-set-membership-constraints-the-values-for-a-column-come-from-a-set-of-discrete-values-or-codes-for-example-a-person-s-sex-may-be-female-male-or-non-binary-foreign-key-constraints-this-is-the-more-general-case-of-set-membership-the-set-of-values-in-a-column-is-defined-in-a-column-of-another-table-that-contains-unique-values-for-example-in-a-us-taxpayer-database-the-state-column-is-required-to-belong-to-one-of-the-us-s-defined-states-or-territories-the-set-of-permissible-states-territories-is-recorded-in-a-separate-state-table-the-term-foreign-key-is-borrowed-from-relational-database-terminology-regular-expression-patterns-occasionally-text-fields-will-have-to-be-validated-this-way-for-example-phone-numbers-may-be-required-to-have-the-pattern-999-999-9999-cross-field-validation-certain-conditions-that-utilize-multiple-fields-must-hold-for-example-in-laboratory-medicine-the-sum-of-the-components-of-the-differential-white-blood-cell-count-must-be-equal-to-100-since-they-are-all-percentages-in-a-hospital-database-a-patient-s-date-of-discharge-from-the-hospital-cannot-be-earlier-than-the-date-of-admission-accuracy-the-degree-of-conformity-of-a-measure-to-a-standard-or-a-true-value-see-also-accuracy-and-precision-accuracy-is-very-hard-to-achieve-through-data-cleansing-in-the-general-case-because-it-requires-accessing-an-external-source-of-data-that-contains-the-true-value-such-gold-standard-data-is-often-unavailable-accuracy-has-been-achieved-in-some-cleansing-contexts-notably-customer-contact-data-by-using-external-databases-that-match-up-zip-codes-to-geographical-locations-city-and-state-and-also-help-verify-that-street-addresses-within-these-zip-codes-actually-exist-completeness-the-degree-to-which-all-required-measures-are-known-incompleteness-is-almost-impossible-to-fix-with-data-cleansing-methodology-one-cannot-infer-facts-that-were-not-captured-when-the-data-in-question-was-initially-recorded-in-some-contexts-e-g-interview-data-it-may-be-possible-to-fix-incompleteness-by-going-back-to-the-original-source-of-data-i-e-re-interviewing-the-subject-but-even-this-does-not-guarantee-success-because-of-problems-of-recall-e-g-in-an-interview-to-gather-data-on-food-consumption-no-one-is-likely-to-remember-exactly-what-one-ate-six-months-ago-in-the-case-of-systems-that-insist-certain-columns-should-not-be-empty-one-may-work-around-the-problem-by-designating-a-value-that-indicates-unknown-or-missing-but-the-supplying-of-default-values-does-not-imply-that-the-data-has-been-made-complete-consistency-the-degree-to-which-a-set-of-measures-are-equivalent-in-across-systems-see-also-consistency-inconsistency-occurs-when-two-data-items-in-the-data-set-contradict-each-other-e-g-a-customer-is-recorded-in-two-different-systems-as-having-two-different-current-addresses-and-only-one-of-them-can-be-correct-fixing-inconsistency-is-not-always-possible-it-requires-a-variety-of-strategies-e-g-deciding-which-data-were-recorded-more-recently-which-data-source-is-likely-to-be-most-reliable-the-latter-knowledge-may-be-specific-to-a-given-organization-or-simply-trying-to-find-the-truth-by-testing-both-data-items-e-g-calling-up-the-customer-uniformity-the-degree-to-which-a-set-data-measures-are-specified-using-the-same-units-of-measure-in-all-systems-see-also-unit-of-measure-in-datasets-pooled-from-different-locales-weight-may-be-recorded-either-in-pounds-or-kilos-and-must-be-converted-to-a-single-measure-using-an-arithmetic-transformation-the-term-integrity-encompasses-accuracy-consistency-and-some-aspects-of-validation-see-also-data-integrity-but-is-rarely-used-by-itself-in-data-cleansing-contexts-because-it-is-insufficiently-specific-for-example-referential-integrity-is-a-term-used-to-refer-to-the-enforcement-of-foreign-key-constraints-above-process-edit-data-auditing-the-data-is-audited-with-the-use-of-statistical-and-database-methods-to-detect-anomalies-and-contradictions-this-eventually-indicates-the-characteristics-of-the-anomalies-and-their-locations-several-commercial-software-packages-will-let-you-specify-constraints-of-various-kinds-using-a-grammar-that-conforms-to-that-of-a-standard-programming-language-e-g-javascript-or-visual-basic-and-then-generate-code-that-checks-the-data-for-violation-of-these-constraints-this-process-is-referred-to-below-in-the-bullets-workflow-specification-and-workflow-execution-for-users-who-lack-access-to-high-end-cleansing-software-microcomputer-database-packages-such-as-microsoft-access-or-file-maker-pro-will-also-let-you-perform-such-checks-on-a-constraint-by-constraint-basis-interactively-with-little-or-no-programming-required-in-many-cases-workflow-specification-the-detection-and-removal-of-anomalies-are-performed-by-a-sequence-of-operations-on-the-data-known-as-the-workflow-it-is-specified-after-the-process-of-auditing-the-data-and-is-crucial-in-achieving-the-end-product-of-high-quality-data-in-order-to-achieve-a-proper-workflow-the-causes-of-the-anomalies-and-errors-in-the-data-have-to-be-closely-considered-workflow-execution-in-this-stage-the-workflow-is-executed-after-its-specification-is-complete-and-its-correctness-is-verified-the-implementation-of-the-workflow-should-be-efficient-even-on-large-sets-of-data-which-inevitably-poses-a-trade-off-because-the-execution-of-a-data-cleansing-operation-can-be-computationally-expensive-post-processing-and-controlling-after-executing-the-cleansing-workflow-the-results-are-inspected-to-verify-correctness-data-that-could-not-be-corrected-during-the-execution-of-the-workflow-is-manually-corrected-if-possible-the-result-is-a-new-cycle-in-the-data-cleansing-process-where-the-data-is-audited-again-to-allow-the-specification-of-an-additional-workflow-to-further-cleanse-the-data-by-automatic-processing-good-quality-source-data-has-to-do-with-data-quality-culture-and-must-be-initiated-at-the-top-of-the-organization-it-is-not-just-a-matter-of-implementing-strong-validation-checks-on-input-screens-because-almost-no-matter-how-strong-these-checks-are-they-can-often-still-be-circumvented-by-the-users-there-is-a-nine-step-guide-for-organizations-that-wish-to-improve-data-quality-3-4-declare-a-high-level-commitment-to-a-data-quality-culture-drive-process-reengineering-at-the-executive-level-spend-money-to-improve-the-data-entry-environment-spend-money-to-improve-application-integration-spend-money-to-change-how-processes-work-promote-end-to-end-team-awareness-promote-interdepartmental-cooperation-publicly-celebrate-data-quality-excellence-continuously-measure-and-improve-data-quality-others-include-parsing-for-the-detection-of-syntax-errors-a-parser-decides-whether-a-string-of-data-is-acceptable-within-the-allowed-data-specification-this-is-similar-to-the-way-a-parser-works-with-grammars-and-languages-data-transformation-data-transformation-allows-the-mapping-of-the-data-from-its-given-format-into-the-format-expected-by-the-appropriate-application-this-includes-value-conversions-or-translation-functions-as-well-as-normalizing-numeric-values-to-conform-to-minimum-and-maximum-values-duplicate-elimination-duplicate-detection-requires-an-algorithm-for-determining-whether-data-contains-duplicate-representations-of-the-same-entity-usually-data-is-sorted-by-a-key-that-would-bring-duplicate-entries-closer-together-for-faster-identification-statistical-methods-by-analyzing-the-data-using-the-values-of-mean-standard-deviation-range-or-clustering-algorithms-it-is-possible-for-an-expert-to-find-values-that-are-unexpected-and-thus-erroneous-although-the-correction-of-such-data-is-difficult-since-the-true-value-is-not-known-it-can-be-resolved-by-setting-the-values-to-an-average-or-other-statistical-value-statistical-methods-can-also-be-used-to-handle-missing-values-which-can-be-replaced-by-one-or-more-plausible-values-which-are-usually-obtained-by-extensive-data-augmentation-algorithms-system-edit-the-essential-job-of-this-system-is-to-find-a-suitable-balance-between-fixing-dirty-data-and-maintaining-the-data-as-close-as-possible-to-the-original-data-from-the-source-production-system-this-is-a-challenge-for-the-extract-transform-load-architect-the-system-should-offer-an-architecture-that-can-cleanse-data-record-quality-events-and-measure-control-quality-of-data-in-the-data-warehouse-a-good-start-is-to-perform-a-thorough-data-profiling-analysis-that-will-help-define-to-the-required-complexity-of-the-data-cleansing-system-and-also-give-an-idea-of-the-current-data-quality-in-the-source-system-s-quality-screens-edit-part-of-the-data-cleansing-system-is-a-set-of-diagnostic-filters-known-as-quality-screens-they-each-implement-a-test-in-the-data-flow-that-if-it-fails-records-an-error-in-the-error-event-schema-quality-screens-are-divided-into-three-categories-column-screens-testing-the-individual-column-e-g-for-unexpected-values-like-null-values-non-numeric-values-that-should-be-numeric-out-of-range-values-etc-structure-screens-these-are-used-to-test-for-the-integrity-of-different-relationships-between-columns-typically-foreign-primary-keys-in-the-same-or-different-tables-they-are-also-used-for-testing-that-a-group-of-columns-is-valid-according-to-some-structural-definition-to-which-it-should-adhere-business-rule-screens-the-most-complex-of-the-three-tests-they-test-to-see-if-data-maybe-across-multiple-tables-follow-specific-business-rules-an-example-could-be-that-if-a-customer-is-marked-as-a-certain-type-of-customer-the-business-rules-that-define-this-kind-of-customer-should-be-adhered-to-when-a-quality-screen-records-an-error-it-can-either-stop-the-dataflow-process-send-the-faulty-data-somewhere-else-than-the-target-system-or-tag-the-data-the-latter-option-is-considered-the-best-solution-because-the-first-option-requires-that-someone-has-to-manually-deal-with-the-issue-each-time-it-occurs-and-the-second-implies-that-data-are-missing-from-the-target-system-integrity-and-it-is-often-unclear-what-should-happen-to-these-data-criticism-of-existing-tools-and-processes-edit-most-data-cleansing-tools-have-limitations-in-usability-project-costs-costs-typically-in-the-hundreds-of-thousands-of-dollars-time-mastering-large-scale-data-cleansing-software-is-time-consuming-security-cross-validation-requires-sharing-information-giving-an-application-access-across-systems-including-sensitive-legacy-systems-error-event-schema-edit-the-error-event-schema-holds-records-of-all-error-events-thrown-by-the-quality-screens-it-consists-of-an-error-event-fact-table-with-foreign-keys-to-three-dimension-tables-that-represent-date-when-batch-job-where-and-screen-who-produced-error-it-also-holds-information-about-exactly-when-the-error-occurred-and-the-severity-of-the-error-also-there-is-an-error-event-detail-fact-table-with-a-foreign-key-to-the-main-table-that-contains-detailed-information-about-in-which-table-record-and-field-the-error-occurred-and-the-error-condition-see-also-edit-data-editing-data-mining-database-repair-iterative-proportional-fitting-record-linkage-single-customer-view-triangulation-social-science-references-edit-wu-s-2013-a-review-on-coarse-warranty-data-and-analysis-pdf-reliability-engineering-and-system-114-1-11-doi-10-1016-j-ress-2012-12-021-data-101-what-is-data-harmonization-datorama-14-april-2017-retrieved-14-august-2019-kimball-r-ross-m-thornthwaite-w-mundy-j-becker-b-the-data-warehouse-lifecycle-toolkit-wiley-publishing-inc-2008-isbn-978-0-470-14977-5-olson-j-e-data-quality-the-accuracy-dimension-morgan-kaufmann-2002-isbn-1-55860-891-5-further-reading-edit-mckinney-wes-2017-data-cleaning-and-preparation-python-for-data-analysis-2nd-ed-o-reilly-pp-195-224-isbn-978-1-4919-5766-0-van-der-loo-mark-de-jonge-edwin-2018-statistical-data-cleaning-with-applications-in-r-hoboken-wiley-isbn-978-1-118-89715-7-external-links-edit-computerworld-data-scrubbing-february-10-2003-erhard-rahm-hong-hai-do-data-cleaning-problems-and-current-approaches-vtedata-augmentation-analysis-archaeology-big-cleansing-collection-compression-corruption-curation-degradation-editing-etl-elt-extract-transform-load-farming-format-management-fusion-integration-integrity-library-lineage-loss-management-migration-mining-philanthropy-pre-processing-preservation-protection-privacy-publishing-recovery-reduction-retention-quality-science-scraping-scrubbing-security-stewardship-storage-validation-warehouse-wrangling-munging-retrieved-from-https-en-wikipedia-org-w-index-php-title-data-cleansing-oldid-1117956020-categories-data-qualitybusiness-intelligencehidden-categories-articles-with-short-descriptionshort-description-is-different-from-wikidata-navigation-menu-personal-tools-not-logged-intalkcontributionscreate-accountlog-in-namespaces-articletalk-english-views-readeditview-history-more-search-navigation-main-pagecontentscurrent-eventsrandom-articleabout-wikipediacontact-usdonate-contribute-helplearn-to-editcommunity-portalrecent-changesupload-file-tools-what-links-hererelated-changesupload-filespecial-pagespermanent-linkpage-informationcite-this-pagewikidata-item-print-export-download-as-pdfprintable-version-languages-l-rby-catalacymraegdeutschespanolfrsyfrancaishangugeoitaliano-brytmagyarnorsk-bokmalo-zbekcha-uzbekcharusskiikhwrdyzhong-wen-edit-links-this-page-was-last-edited-on-24-october-2022-at-12-34-utc-text-is-available-under-the-creative-commons-attribution-sharealike-license-3-0-additional-terms-may-apply-by-using-this-site-you-agree-to-the-terms-of-use-and-privacy-policy-wikipedia-r-is-a-registered-trademark-of-the-wikimedia-foundation-inc-a-non-profit-organization-privacy-policy-about-wikipedia-disclaimers-contact-wikipedia-mobile-view-developers-statistics-cookie-statement